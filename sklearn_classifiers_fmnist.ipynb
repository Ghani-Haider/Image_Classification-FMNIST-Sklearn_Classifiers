{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import csv\r\n",
    "import pandas as pd\r\n",
    "import sklearn\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn import datasets, svm, metrics\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def load_file(fileName):\r\n",
    "    dataset = pd.read_table(fileName, header=0, sep=\",\", encoding=\"unicode_escape\")\r\n",
    "    return dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# splitting the training and test dataset\r\n",
    "print(\"Loading data.....\")\r\n",
    "dataset_train = load_file(\"fashion-mnist_train.csv\")\r\n",
    "dataset_test = load_file(\"fashion-mnist_test.csv\")\r\n",
    "\r\n",
    "# splitting training data\r\n",
    "trainingY = dataset_train['label']\r\n",
    "trainingX = dataset_train.drop(columns='label')\r\n",
    "\r\n",
    "# splitting training data \r\n",
    "testY = dataset_test['label']\r\n",
    "testX = dataset_test.drop(columns='label')\r\n",
    "\r\n",
    "# normaling the input values\r\n",
    "trainingX = trainingX/255\r\n",
    "testX = testX/255"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading data.....\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "### Support Vector Classifier ###\r\n",
    "clf = svm.SVC(gamma=0.001)\r\n",
    "# learning the model\r\n",
    "clf.fit(trainingX, trainingY)\r\n",
    "# calssifying the test dataset\r\n",
    "predicted = clf.predict(testX)\r\n",
    "# evaluating the predicted result\r\n",
    "print(\"Metrics for Support Vector Classifier\")\r\n",
    "print('Accuracy:', metrics.accuracy_score(predicted, testY))\r\n",
    "print('Precision:', metrics.precision_score(predicted, testY, average=None))\r\n",
    "print('Recall:', metrics.recall_score(predicted, testY, average=None))\r\n",
    "print('F_measure:', metrics.f1_score(predicted, testY, average=None))\r\n",
    "print('Confusion Matrix:', metrics.confusion_matrix(predicted, testY))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics for Support Vector Classifier\n",
      "Accuracy: 0.856\n",
      "Precision: [0.848 0.959 0.762 0.908 0.836 0.914 0.553 0.887 0.96  0.933]\n",
      "Recall: [0.76190476 0.98358974 0.78963731 0.85098407 0.78130841 0.92697769\n",
      " 0.69647355 0.89056225 0.9495549  0.91202346]\n",
      "F_measure: [0.80265026 0.97113924 0.77557252 0.87856797 0.80772947 0.9204431\n",
      " 0.61649944 0.88877756 0.95474888 0.92239249]\n",
      "Confusion Matrix: [[848   5  14  28   1   1 213   0   3   0]\n",
      " [  2 959   1  10   0   0   3   0   0   0]\n",
      " [ 12   9 762  17  59   0  98   0   8   0]\n",
      " [ 55  23  11 908  31   1  34   0   4   0]\n",
      " [  0   0 135  17 836   0  81   0   1   0]\n",
      " [  3   1   1   0   0 914   0  42   5  20]\n",
      " [ 68   3  67  17  71   1 553   0  14   0]\n",
      " [  0   0   0   0   0  60   0 887   2  47]\n",
      " [ 12   0   9   3   2   6  18   1 960   0]\n",
      " [  0   0   0   0   0  17   0  70   3 933]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "### SGD Classifier ###\r\n",
    "classifier = sklearn.linear_model.SGDClassifier()\r\n",
    "# learning the model\r\n",
    "classifier.fit(trainingX,trainingY)\r\n",
    "# calssifying the test dataset\r\n",
    "predicted3=classifier.predict(testX)\r\n",
    "# evaluating the predicted result\r\n",
    "print(\"Metrics for SGD Classifier\")\r\n",
    "print('Accuracy:', metrics.accuracy_score(predicted3, testY))\r\n",
    "print('Precision:', metrics.precision_score(predicted3, testY, average=None))\r\n",
    "print('Recall:', metrics.recall_score(predicted3, testY, average=None))\r\n",
    "print('F_measure:', metrics.f1_score(predicted3, testY, average=None))\r\n",
    "print('Confusion Matrix:', metrics.confusion_matrix(predicted3, testY))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics for SGD Classifier\n",
      "Accuracy: 0.8456\n",
      "Precision: [0.858 0.979 0.726 0.88  0.89  0.927 0.445 0.869 0.955 0.927]\n",
      "Recall: [0.75461741 0.95886386 0.79257642 0.84130019 0.70189274 0.88963532\n",
      " 0.7834507  0.92941176 0.9026465  0.91873142]\n",
      "F_measure: [0.80299485 0.96882731 0.75782881 0.86021505 0.78483245 0.9079334\n",
      " 0.56760204 0.89819121 0.92808552 0.92284719]\n",
      "Confusion Matrix: [[858   4  23  35   3   2 208   0   4   0]\n",
      " [  3 979   2  22   3   3   7   0   2   0]\n",
      " [ 15   0 726  14  45   2 107   0   7   0]\n",
      " [ 52  13  14 880  28   1  48   0  10   0]\n",
      " [  6   1 180  30 890   0 156   0   4   1]\n",
      " [  3   2   0   0   1 927   0  65   7  37]\n",
      " [ 35   1  38  11  28   1 445   0   6   3]\n",
      " [  0   0   0   0   0  35   0 869   2  29]\n",
      " [ 28   0  17   8   2  13  29   3 955   3]\n",
      " [  0   0   0   0   0  16   0  63   3 927]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "### Logistic Regression Classifier ###\r\n",
    "classifier = LogisticRegression()\r\n",
    "# learning the model\r\n",
    "classifier.fit(trainingX,trainingY)\r\n",
    "# calssifying the test dataset\r\n",
    "predicted4 = classifier.predict(testX)\r\n",
    "# evaluating the predicted result\r\n",
    "print(\"Metrics for Logistic Regression\")\r\n",
    "print('Accuracy:', metrics.accuracy_score(predicted4, testY))\r\n",
    "print('Precision:', metrics.precision_score(predicted4, testY, average=None))\r\n",
    "print('Recall:', metrics.recall_score(predicted4, testY, average=None))\r\n",
    "print('F_measure:', metrics.f1_score(predicted4, testY, average=None))\r\n",
    "print('Confusion Matrix:', metrics.confusion_matrix(predicted4, testY))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics for Logistic Regression\n",
      "Accuracy: 0.8565\n",
      "Precision: [0.813 0.971 0.759 0.887 0.809 0.922 0.6   0.911 0.951 0.942]\n",
      "Recall: [0.8049505  0.971      0.76512097 0.85866409 0.77639155 0.92663317\n",
      " 0.66006601 0.91191191 0.93786982 0.93638171]\n",
      "F_measure: [0.80895522 0.971      0.76204819 0.87260207 0.79236043 0.92431078\n",
      " 0.62860136 0.91145573 0.94438928 0.93918245]\n",
      "Confusion Matrix: [[813   0  16  27   1   2 146   0   5   0]\n",
      " [  4 971   2  19   0   1   3   0   0   0]\n",
      " [ 16   3 759  18  84   0 105   0   7   0]\n",
      " [ 46  17  12 887  29   1  34   0   7   0]\n",
      " [  0   1 111  22 809   0  95   0   4   0]\n",
      " [  2   2   0   0   0 922   1  44   6  18]\n",
      " [ 98   6  90  26  74   1 600   0  14   0]\n",
      " [  0   0   0   0   0  46   0 911   4  38]\n",
      " [ 20   0  10   1   3  10  16   1 951   2]\n",
      " [  1   0   0   0   0  17   0  44   2 942]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "### K-Neighbors Classifier ###\r\n",
    "classifier = KNeighborsClassifier()\r\n",
    "# learning the model\r\n",
    "classifier.fit(trainingX,trainingY)\r\n",
    "# calssifying the test dataset\r\n",
    "predicted5=classifier.predict(testX)\r\n",
    "# evaluating the predicted result\r\n",
    "print(\"Metrics for KNeighborsClassifier\")\r\n",
    "print('Accuracy:', metrics.accuracy_score(predicted5, testY))\r\n",
    "print('Precision:', metrics.precision_score(predicted5, testY, average=None))\r\n",
    "print('Recall:', metrics.recall_score(predicted5, testY, average=None))\r\n",
    "print('F_measure:', metrics.f1_score(predicted5, testY, average=None))\r\n",
    "print('Confusion Matrix:', metrics.confusion_matrix(predicted5, testY))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics for KNeighborsClassifier\n",
      "Accuracy: 0.8589\n",
      "Precision: [0.874 0.965 0.808 0.882 0.799 0.816 0.583 0.945 0.953 0.964]\n",
      "Recall: [0.76599474 0.98569969 0.75302889 0.91304348 0.78719212 0.99512195\n",
      " 0.68187135 0.87177122 0.9774359  0.88278388]\n",
      "F_measure: [0.81644092 0.97524002 0.77954655 0.89725331 0.79305211 0.8967033\n",
      " 0.62857143 0.90690979 0.96506329 0.92160612]\n",
      "Confusion Matrix: [[874   4  18  36   4   1 202   0   2   0]\n",
      " [  1 965   0  11   0   0   1   0   1   0]\n",
      " [ 16   7 808  14  99   1 114   0  14   0]\n",
      " [ 11  14  14 882  26   1  16   0   2   0]\n",
      " [  5   1  98  32 799   0  74   0   6   0]\n",
      " [  0   0   0   0   0 816   0   1   1   2]\n",
      " [ 86   9  61  25  70   8 583   0  13   0]\n",
      " [  2   0   0   0   0  98   0 945   5  34]\n",
      " [  5   0   1   0   2   4  10   0 953   0]\n",
      " [  0   0   0   0   0  71   0  54   3 964]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "### Random Forest Classifier ###\r\n",
    "clf = RandomForestClassifier()\r\n",
    "# learning the model\r\n",
    "clf.fit(trainingX, trainingY)\r\n",
    "# calssifying the test dataset\r\n",
    "predicted = clf.predict(testX)\r\n",
    "# evaluating the predicted result\r\n",
    "print(\"Metrics for Random Forest Classifier\")\r\n",
    "print('Accuracy:', metrics.accuracy_score(predicted, testY))\r\n",
    "print('Precision:', metrics.precision_score(predicted, testY, average=None))\r\n",
    "print('Recall:', metrics.recall_score(predicted, testY, average=None))\r\n",
    "print('F_measure:', metrics.f1_score(predicted, testY, average=None))\r\n",
    "print('Confusion Matrix:', metrics.confusion_matrix(predicted, testY))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metrics for Random Forest Classifier\n",
      "Accuracy: 0.8854\n",
      "Precision: [0.864 0.97  0.803 0.931 0.867 0.942 0.619 0.932 0.977 0.949]\n",
      "Recall: [0.81050657 0.99080695 0.8185525  0.89261745 0.80426716 0.97113402\n",
      " 0.74043062 0.91913215 0.95784314 0.93682132]\n",
      "F_measure: [0.83639884 0.98029308 0.81070167 0.9114048  0.83445621 0.95634518\n",
      " 0.67429194 0.92552135 0.96732673 0.94287134]\n",
      "Confusion Matrix: [[864   3   6  19   1   0 172   0   1   0]\n",
      " [  0 970   1   7   0   0   0   0   1   0]\n",
      " [ 11   4 803  10  54   0  92   0   7   0]\n",
      " [ 30  16   8 931  29   0  29   0   0   0]\n",
      " [  0   1 112  18 867   0  76   0   4   0]\n",
      " [  1   1   0   0   0 942   0  17   1   8]\n",
      " [ 83   5  61  15  46   0 619   0   6   1]\n",
      " [  0   0   0   0   0  41   0 932   2  39]\n",
      " [ 11   0   9   0   3   5  12   0 977   3]\n",
      " [  0   0   0   0   0  12   0  51   1 949]]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}